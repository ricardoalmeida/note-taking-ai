# Story 1.3: Voice Recording and AI Transcription

## Status
Draft

## Story
**As a** professional user,
**I want** to record audio directly in the app and automatically convert it to text notes with AI enhancement,
**so that** I can capture spoken information during meetings or thoughts without manual typing.

## Acceptance Criteria
1. Users can record audio directly in the browser with start/stop/pause controls
2. AI transcription automatically converts recorded audio to text with high accuracy
3. Option to enhance transcripts with AI summarization or convert to structured notes
4. Existing notes system seamlessly stores voice-to-text content as regular notes
5. New functionality follows existing oRPC API pattern for audio upload and processing
6. Integration with current AI SDK infrastructure for consistent transcription quality
7. Audio recording and transcription covered by appropriate tests including permission handling
8. Voice recording UI follows existing Shadcn-ui patterns with clear recording status indicators
9. No regression in existing note creation or AI processing functionality verified

## Tasks / Subtasks

- [ ] Task 1: Extend Notes Schema for Audio Support (AC: 4, 5)
  - [ ] Add audio metadata fields to existing notes table: audio_file_path, audio_duration, transcription_status
  - [ ] Create audio_transcriptions table with: id, note_id, original_audio_path, transcribed_text, confidence_score
  - [ ] Add transcription_status enum: 'recording', 'uploaded', 'transcribing', 'completed', 'failed'
  - [ ] Set up proper relationships between notes and audio transcriptions
  - [ ] Run database migration to extend existing schema

- [ ] Task 2: Implement Browser Audio Recording (AC: 1, 8)
  - [ ] Create audio recording hook using Web Audio API in `apps/web/src/hooks/`
  - [ ] Implement microphone permission handling with user-friendly prompts
  - [ ] Add audio recording controls: start, stop, pause, resume functionality
  - [ ] Create audio waveform visualization during recording
  - [ ] Add recording time display and audio level indicators

- [ ] Task 3: Build Audio Recording UI Components (AC: 1, 8)
  - [ ] Create voice recording component in `apps/web/src/components/voice/`
  - [ ] Design recording control interface with clear visual feedback
  - [ ] Add recording status indicators and permission request UI
  - [ ] Implement audio playback controls for recorded audio
  - [ ] Follow Shadcn-ui design patterns and accessibility standards

- [ ] Task 4: Implement Audio Upload and Storage (AC: 5)
  - [ ] Create audio upload endpoint in existing notes router
  - [ ] Add audio file validation (format, duration, size limits)
  - [ ] Implement secure audio file storage with proper naming
  - [ ] Add audio metadata extraction and storage
  - [ ] Handle chunked upload for larger audio files

- [ ] Task 5: Integrate AI Transcription Service (AC: 2, 6)
  - [ ] Implement audio transcription using Vercel AI SDK capabilities
  - [ ] Add transcription accuracy and confidence scoring
  - [ ] Create transcription status tracking and progress updates
  - [ ] Implement error handling for transcription failures
  - [ ] Add retry logic for failed transcription attempts

- [ ] Task 6: Build Transcript Enhancement Features (AC: 3, 6)
  - [ ] Create transcript editing interface with text corrections
  - [ ] Add AI summarization options for transcribed content
  - [ ] Implement structured note conversion from transcripts
  - [ ] Add speaker identification and timestamps (basic implementation)
  - [ ] Create transcript export and sharing capabilities

- [ ] Task 7: Integrate with Notes System (AC: 4, 9)
  - [ ] Extend existing note creation flow to include voice notes
  - [ ] Add voice note display in notes list with audio indicators
  - [ ] Implement seamless switching between text and voice note editing
  - [ ] Add search functionality across transcribed voice content
  - [ ] Maintain compatibility with existing note features (tags, folders)

- [ ] Task 8: Client-Side Audio Integration (AC: 5, 7)
  - [ ] Extend oRPC client for audio operations
  - [ ] Integrate TanStack Query for audio upload progress and transcription status
  - [ ] Add real-time status updates for transcription progress
  - [ ] Implement proper error handling for browser compatibility issues
  - [ ] Add offline recording capability with sync when online

- [ ] Task 9: Testing Implementation (AC: 7, 9)
  - [ ] Write unit tests for audio recording hooks and transcription APIs
  - [ ] Create E2E tests for voice recording, transcription, and note integration workflows
  - [ ] Test browser permission handling and compatibility across browsers
  - [ ] Verify transcription accuracy with sample audio files
  - [ ] Test integration with existing notes and AI functionality

## Dev Notes

### Testing Standards
**Location**: E2E tests in `tests/e2e/`, unit tests co-located with source files
**Framework**: Playwright for E2E testing, Bun test runner for unit tests
**Standards**: [Source: architecture.md#Testing Architecture]
- Mock Web Audio API for consistent testing across environments
- Test audio file processing with sample recordings
- Verify browser permission handling in different scenarios
- Test transcription integration with mock AI responses

### Architecture Context

**Technology Stack**: [Source: architecture.md#Technology Stack]
- **Backend**: Next.js API Routes, oRPC (1.8.6), Drizzle ORM (0.44.2), SQLite with LibSQL
- **Frontend**: Next.js 15.5.0 with App Router, TanStack Query (5.85.5), Shadcn-ui, Tailwind CSS
- **AI Integration**: Vercel AI SDK (5.0.39) with Google AI SDK for transcription
- **Audio APIs**: Web Audio API, MediaRecorder API for browser-based recording

**Project Structure**: [Source: architecture.md#Project Structure]
- **Database Schemas**: `apps/server/src/db/schema/` (extend notes.ts)
- **API Routers**: `apps/server/src/routers/` (extend notes.ts)
- **Frontend Components**: `apps/web/src/components/voice/`
- **Audio Storage**: Secure directory structure for audio files

**Database Architecture**: [Source: architecture.md#Database Architecture]
- Extends existing notes table from Story 1.1
- Audio metadata integrated with note records
- Transcription data stored separately for flexibility
- Proper indexing for audio search and retrieval

**AI Integration**: [Source: architecture.md#AI Integration]
- Existing Vercel AI SDK integration patterns from Stories 1.1 and 1.2
- Google AI SDK speech-to-text capabilities
- Consistent error handling and response formatting
- Integration with existing AI processing pipeline

**Frontend Architecture**: [Source: architecture.md#Frontend Architecture]
- **Component Structure**: Voice components follow Shadcn-ui patterns
- **State Management**: TanStack Query for audio upload and transcription status
- **Browser APIs**: Web Audio API for recording, MediaRecorder for file generation
- **Accessibility**: Keyboard navigation and screen reader support for audio controls

**Security Considerations**: [Source: architecture.md#Security Considerations]
- Microphone permission handling with user consent
- Secure audio file storage with user-based access controls
- Audio file validation to prevent malicious uploads
- Transcription data privacy and user ownership

### File Locations
- **Extended Notes Schema**: `apps/server/src/db/schema/notes.ts` (add audio fields)
- **Audio Transcription Schema**: `apps/server/src/db/schema/audio-transcriptions.ts`
- **Voice Recording Hook**: `apps/web/src/hooks/useAudioRecording.ts`
- **Voice Components**: `apps/web/src/components/voice/`
- **Voice Note Pages**: `apps/web/src/app/notes/voice/`
- **E2E Tests**: `tests/e2e/voice-notes.spec.ts`

### Technical Constraints
- Browser compatibility for Web Audio API (modern browsers only)
- Audio file size limits for storage and processing efficiency
- Transcription processing time considerations for user experience
- Must integrate seamlessly with existing notes system from Story 1.1
- Follow oRPC patterns for all API communications

### Dependencies
- **Required**: Story 1.1 (Manual Notes) must be completed for notes system integration
- **Builds on**: Existing authentication, database, and AI infrastructure
- **Extends**: Notes database schema and API endpoints from Story 1.1

### Browser Compatibility Notes
- **Supported**: Chrome 66+, Firefox 55+, Safari 11+, Edge 79+
- **Required APIs**: MediaRecorder, Web Audio API, getUserMedia
- **Fallbacks**: Graceful degradation for unsupported browsers
- **Permissions**: Microphone access required with proper user consent flow

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-28 | 1.0 | Initial story creation | Scrum Master (Bob) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*Results from QA Agent review will be populated here after implementation*